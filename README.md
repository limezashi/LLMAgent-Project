# ğŸ¤– LLMAgent - Projeto de Agente de Linguagem com Gemma

Este projeto implementa um Agente de Linguagem utilizando o modelo **Gemma-2b-it** da Google. O objetivo principal Ã© carregar o modelo e criar um pipeline de geraÃ§Ã£o de texto para tarefas de InteligÃªncia Artificial.

## ğŸš€ ComeÃ§ando

Siga estas instruÃ§Ãµes para configurar e rodar o projeto em sua mÃ¡quina local.

### PrÃ©-requisitos

VocÃª precisarÃ¡ ter o Python instalado. Ã‰ altamente recomendado o uso de um ambiente virtual (`venv`).

1.  **Crie e Ative o Ambiente Virtual:**
    ```bash
    python3 -m venv venv
    source venv/bin/activate  # macOS/Linux
    .\venv\Scripts\activate   # Windows
    ```

2.  **Instale as DependÃªncias:**
    *(Assumindo que vocÃª usa `transformers`, `torch` e `huggingface_hub`)*
    ```bash
    pip install transformers torch huggingface-hub
    ```

### ğŸ”‘ AutenticaÃ§Ã£o no Hugging Face

O modelo `google/gemma-2b-it` Ã© um modelo de acesso restrito ("Gated Model"). VocÃª deve estar autenticado no Hugging Face Hub para baixÃ¡-lo.

1.  **Obtenha o Token:** Certifique-se de que vocÃª **aceitou os termos do modelo** na pÃ¡gina do Hugging Face e **gerou um Token de Acesso** (com permissÃ£o de **Read**).
2.  **FaÃ§a o Login:** Use a Command Line Interface (CLI) para autenticar seu ambiente:
    ```bash
    huggingface-cli login
    # Cole o seu Token de Acesso quando solicitado.
    ```
    *(VocÃª tambÃ©m pode usar o novo comando: `hf auth login`)*

### âš™ï¸ Executando o Projeto

O script principal Ã© o `agent_app.py`.

Para executar o agente e carregar o modelo:

```bash
python agent_app.py

#### Atividade elaborada em grupo:
- Gabriel Campari
- Gabriel Henrique Imolene
- Glenda Borges
- Gustavo Almeida 
- Kaue Barbi
- LÃ­via Mezashi